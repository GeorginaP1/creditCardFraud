{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card Fraud Detection Project\n",
    "### Project Summary\n",
    "This project aims to train a classifier that can robustly detect fraudulent credit card transactions\n",
    "### Dataset\n",
    "An open source dataset containing credit card transactions from European cardholders in September 2013.\n",
    "\n",
    "### Notes:\n",
    "- The dataset is unbalanced and only contains 0.172% fraudulent transactions\n",
    "\n",
    "\n",
    "- The dataset is anonymised and transformed into PCA data, original features are confidential\n",
    "\n",
    "- Features V1, ..., V28 are PCA\n",
    "\n",
    "- Users are recommended to use Area Under the Precision-Recall Curve (AUPRC) to improve accuracy due to issues from the imbalanced dataset  \n",
    "\n",
    "### Acknowledgements\n",
    "This project was completed with help from a tutorial by Pranjal Saxena found __[here](https://towardsdatascience.com/credit-card-fraud-detection-using-machine-learning-python-5b098d4a8edc)__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Necessary library imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 600x300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Packages related to general operating system & warnings\n",
    "import os \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#Packages related to data importing, manipulation, exploratory data #analysis, data understanding\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from termcolor import colored as cl # text customization\n",
    "#Packages related to data visualizaiton\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#Setting plot sizes and type of plot\n",
    "plt.rc(\"font\", size=14)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.gray()\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "from sklearn.preprocessing import  PolynomialFeatures, KBinsDiscretizer, FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer, OrdinalEncoder\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa as tsa\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, ElasticNet, Lasso, Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz, export_text\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor,RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor, AdaBoostClassifier, AdaBoostRegressor \n",
    "from sklearn.svm import LinearSVC, LinearSVR, SVC, SVR\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Dataset import\n",
    "data = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Investigating the distribution of data (bisaed towards clean transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num of transactions: 284807\u001b[0m\n",
      "Total num of normal transactions: 284315\u001b[0m\n",
      "Total num of fraudulent transactions: 492\u001b[0m\n",
      "Percentage of fraudulent transactions: 0.17\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Total_transactions = len(data)\n",
    "normal = len(data[data.Class == 0])\n",
    "fraudulent = len(data[data.Class == 1])\n",
    "fraud_percent = round(fraudulent/normal*100, 2)\n",
    "print(cl('Total num of transactions: {}'.format(Total_transactions)))\n",
    "print(cl('Total num of normal transactions: {}'.format(normal)))\n",
    "print(cl('Total num of fraudulent transactions: {}'.format(fraudulent)))\n",
    "print(cl('Percentage of fraudulent transactions: {}'.format(fraud_percent)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
